# get stdlib modules
from pathlib import Path

# get local modules
from utils.utils_counts import CountsUtils
from utils.utils_pipeline import PipelineUtils

# define data flow directories
work_dir: Path = Path(config["work_dir"])
input_dir: Path = Path(f'{work_dir}/{config["results"]}/{config["input_dir"]}')
output_dir: Path = Path(f'{work_dir}/{config["results"]}/{config["output_dir"]}')

# define log & benchmark directories
log_dir: Path = Path(f'{output_dir}/{config["log_dir"]}')
benchmarks_dir: Path = Path(f'{output_dir}/{config["benchmarks_dir"]}')

# generate flattened samples list
flattended_samples: list = []
flattended_samples.extend(config["sample_groups"]["control"])
flattended_samples.extend(config["sample_groups"]["condition"])

# get available resources
memory: float = PipelineUtils.get_available_memory()
cores: int = PipelineUtils.get_max_cores()

# generate a list of all files to be generated by rule `all` (terminal files)
terminal_files: list = CountsUtils.generate_terminal_files(
    out_dir=output_dir,
)


rule all:
    """
    Generate all terminal files for the snakemake rule(s) below
    """
    input:
        terminal_files,
    output:
        temp(touch(f"{work_dir}/progress/counts.done")),


rule run_featurecounts:
    """
    Runs featurecounts and generates counts output for
    mapped reads for genomic features
    """
    input:
        bam_list=expand(
            "{input_dir}/{sample}_Aligned.sortedByCoord.out.bam",
            input_dir=input_dir,
            sample=flattended_samples,
        ),
        gtf=work_dir / "chr22_genes.gtf",
    output:
        counts_out=output_dir / "counts.out",
        final_out=output_dir / "final_counts.out",
        counts_summary=output_dir / "counts.out.summary",
    params:
        count_read_pairs="--countReadPairs"
        if config["sample_type"] == "paired-end"
        else "",
        paired_end="-p" if config["sample_type"] == "paired-end" else "",
    conda:
        "../envs/env_counts.yaml"
    message:
        "Running FeatureCounts for {input.bam_list}"
    log:
        log_dir / "featurecounts.log",
    benchmark:
        benchmarks_dir / "featurecounts.benchmark.txt"
    threads: cores * 2
    resources:
        mem_gb=memory,
    shell:
        """
        featureCounts \
        -a {input.gtf} \
        -o {output.counts_out} \
        {input.bam_list} \
        -T {threads} \
        {params.count_read_pairs} \
        {params.paired_end} \
        &> {log}

        sed -i '1d' {output.counts_out}
        cut -f1,7- {output.counts_out} > {output.final_out}
        """
