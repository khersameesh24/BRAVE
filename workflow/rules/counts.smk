# get stdlib modules
from pathlib import Path

# get local modules
from utils.utils_counts import CountsUtils

# define data flow directories
work_dir: Path = Path(config["work_dir"])
input_dir: Path = Path(f'{work_dir}/{config["results"]}/{config["input_dir"]}')
output_dir: Path = Path(f'{work_dir}/{config["results"]}/{config["output_dir"]}')

# define log & benchmark directories
log_dir: Path = Path(f'{output_dir}/{config["log_dir"]}')
benchmarks_dir: Path = Path(f'{output_dir}/{config["benchmarks_dir"]}')

# generate flattened samples list
flattended_samples: list = []
flattended_samples.extend(config["sample_groups"]["control"])
flattended_samples.extend(config["sample_groups"]["condition"])

# generate a list of all files to be generated by rule `all` (terminal files)
terminal_files: list = CountsUtils.generate_terminal_files(
    out_dir=output_dir,
)


rule all:
    """
    Generate all terminal files for the snakemake rule(s) below
    """
    input:
        terminal_files,
    output:
        temp(touch(f"{work_dir}/progress/counts.done")),


rule run_featurecounts:
    """
    Runs featurecounts and generates counts output for
    mapped reads for genomic features
    """
    input:
        bam_list=[
            f"{input_dir}/{sample}_Aligned.sortedByCoord.out.bam"
            for sample in flattended_samples
        ],
        gtf=work_dir / "chr22_genes.gtf",
    output:
        counts_out=output_dir / "counts.out",
        counts_summary=output_dir / "counts.out.summary",
    conda:
        "../envs/env_counts.yaml"
    message:
        "Running FeatureCounts for {input.bam_list}"
    log:
        log_dir / "featurecounts.log",
    benchmark:
        benchmarks_dir / "featurecounts.benchmark.txt"
    threads: config["threads"]
    resources:
        mem_gb=4,
    shell:
        """
        featureCounts \
        -a {input.gtf} \
        -o {output.counts_out} \
        {input.bam_list} \
        &> {log}
        """
